{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.45.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rajan mishra ji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajan Mishra Ji\\AppData\\Local\\Temp\\ipykernel_4340\\673245617.py:13: DtypeWarning: Columns (1,7,8,16,17,18,19,20,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv(train_data_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in training data:\n",
      " Index(['ID', 'Client_Income', 'Car_Owned', 'Bike_Owned', 'Active_Loan',\n",
      "       'House_Own', 'Child_Count', 'Credit_Amount', 'Loan_Annuity',\n",
      "       'Accompany_Client', 'Client_Income_Type', 'Client_Education',\n",
      "       'Client_Marital_Status', 'Client_Gender', 'Loan_Contract_Type',\n",
      "       'Client_Housing_Type', 'Population_Region_Relative', 'Age_Days',\n",
      "       'Employed_Days', 'Registration_Days', 'ID_Days', 'Own_House_Age',\n",
      "       'Mobile_Tag', 'Homephone_Tag', 'Workphone_Working', 'Client_Occupation',\n",
      "       'Client_Family_Members', 'Cleint_City_Rating',\n",
      "       'Application_Process_Day', 'Application_Process_Hour',\n",
      "       'Client_Permanent_Match_Tag', 'Client_Contact_Work_Tag',\n",
      "       'Type_Organization', 'Score_Source_1', 'Score_Source_2',\n",
      "       'Score_Source_3', 'Social_Circle_Default', 'Phone_Change',\n",
      "       'Credit_Bureau', 'Default'],\n",
      "      dtype='object')\n",
      "No suitable target variable ('default' or 'target') found in training dataset. Check column names or dataset structure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajan Mishra Ji\\AppData\\Local\\Temp\\ipykernel_4340\\673245617.py:14: DtypeWarning: Columns (7,8,16,17,18,19,20,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data = pd.read_csv(test_data_file)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Target variable not found.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo suitable target variable (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) found in training dataset. Check column names or dataset structure.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget variable not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Assign target variable and features\u001b[39;00m\n\u001b[0;32m     36\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_data[target_variable]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Target variable not found.'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# File paths\n",
    "train_data_file = r'C:\\Users\\Rajan Mishra Ji\\Downloads\\Train_Dataset.csv'\n",
    "test_data_file = r'C:\\Users\\Rajan Mishra Ji\\Downloads\\Test_Dataset.csv'\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    train_data = pd.read_csv(train_data_file)\n",
    "    test_data = pd.read_csv(test_data_file)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Ensure the dataset files are in the correct directory.\")\n",
    "    raise\n",
    "\n",
    "# Verify the column names in training data\n",
    "print(\"Columns in training data:\\n\", train_data.columns)\n",
    "\n",
    "# Check for 'default' or 'target' columns\n",
    "target_variable = None\n",
    "if 'default' in train_data.columns:\n",
    "    target_variable = 'default'\n",
    "    print(\"Found 'default' column in training dataset. Proceeding with it as target variable.\")\n",
    "elif 'target' in train_data.columns:\n",
    "    target_variable = 'target'\n",
    "    print(\"Found 'target' column in training dataset. Proceeding with it as target variable.\")\n",
    "else:\n",
    "    print(\"No suitable target variable ('default' or 'target') found in training dataset. Check column names or dataset structure.\")\n",
    "    raise KeyError(\"Target variable not found.\")\n",
    "\n",
    "# Assign target variable and features\n",
    "y_train = train_data[target_variable]\n",
    "X_train = train_data.drop(['ID', target_variable], axis=1)  # Assuming 'ID' and target_variable are dropped for training\n",
    "\n",
    "# Explore the dataset\n",
    "print(\"Train Data Head:\\n\", X_train.head())\n",
    "print(\"\\nTrain Data Info:\\n\", X_train.info())\n",
    "print(\"\\nTrain Data Description:\\n\", X_train.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Train Data:\\n\", X_train.isnull().sum())\n",
    "print(\"\\nMissing Values in Test Data:\\n\", test_data.isnull().sum())\n",
    "\n",
    "# Clean the dataset by removing non-numeric characters\n",
    "def clean_numeric_columns(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    return df\n",
    "\n",
    "X_train = clean_numeric_columns(X_train)\n",
    "test_data = clean_numeric_columns(test_data)\n",
    "\n",
    "# Handle missing values (if any)\n",
    "X_train = X_train.fillna(X_train.median())\n",
    "test_data = test_data.fillna(test_data.median())\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for column in X_train.select_dtypes(include=['object']).columns:\n",
    "    X_train[column] = le.fit_transform(X_train[column].astype(str))\n",
    "for column in test_data.select_dtypes(include=['object']).columns:\n",
    "    test_data[column] = le.transform(test_data[column].astype(str))\n",
    "\n",
    "# Ensure all columns are now numeric\n",
    "print(\"\\nTrain Data Types:\\n\", X_train.dtypes)\n",
    "print(\"\\nTest Data Types:\\n\", test_data.dtypes)\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "test_data_scaled = scaler.transform(test_data.drop('ID', axis=1))\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy: \", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = model.predict(test_data_scaled)\n",
    "\n",
    "# Prepare the submission\n",
    "submission = pd.DataFrame({'ID': test_data['ID'], target_variable: test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created: submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
